{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_Mechanism_Attention_Translation",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szRTSvEGLLkj"
      },
      "source": [
        "# Translate seq2seq Mechanism Attention  \n",
        "По примеру https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3GUs1d6LZNm"
      },
      "source": [
        "#Step 1: Import the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbFfACt8LdDP",
        "outputId": "a9104703-9e58-490a-f300-7d6b36bd2465"
      },
      "source": [
        "!!curl -O http://www.manythings.org/anki/fra-eng.zip\n",
        "!!unzip fra-eng.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Archive:  fra-eng.zip',\n",
              " '  inflating: _about.txt              ',\n",
              " '  inflating: fra.txt                 ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHGkW-KfL7Dz"
      },
      "source": [
        "# Get the txt file which has English -> French translation\n",
        "path_to_file = \"fra.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lyDl22DMAN9"
      },
      "source": [
        "#Step 2: Preprocess the Dataset\n",
        "The dataset has Unicode characters, which have to be normalized.\n",
        "\n",
        "Moreover, all the tokens in the sequences have to be cleaned using the regular expressions library.\n",
        "\n",
        "Remove unwanted spaces, include a space between every word and the punctuation following it (to differentiate between both), replace unwanted characters with spaces, and append <start> and <end> tokens to specify the start and end of a sequence.\n",
        "\n",
        "Encapsulate the unicode conversion in a function unicode_to_ascii() and sequence preprocessing in a function preprocess_sentence()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5kXbWDVMB_-"
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "import re\n",
        "\n",
        "# Convert the unicode sequence to ascii\n",
        "# вот этого у нас не было\n",
        "def unicode_to_ascii(s):\n",
        "\n",
        "  # Normalize the unicode string and remove the non-spacking mark\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "# Preprocess the sequence\n",
        "def preprocess_sentence(w):\n",
        "\n",
        "  # Clean the sequence\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # Create a space between word and the punctuation following it\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # Replace everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  #w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "  # сделаем универсальным и для русских текстов\n",
        "  w = re.sub(r\"[^a-zA-Zа-яёА-ЯЁ?.!,;:¿]+\", \" \", w) # добавим еще букуву '¿' из оригинала\n",
        "  # Перевёрнутый вопросительный знак в испанском языке ставят в начале вопросительного предложения \n",
        "  #и он является усиливающим дополнением к традиционному во всех языках вопросительному знаку.\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # Add a start and stop token to detect the start and end of the sequence\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEPIpJ70NUti"
      },
      "source": [
        "#Step 3: Prepare the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGlBtei7NZaF"
      },
      "source": [
        "#Next, prepare a dataset out of the raw data we have. Create word pairs combining the English sequences and their related French sequences.\n",
        "\n",
        "import io\n",
        "\n",
        "# Create the Dataset\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  # Loop through lines (sequences) and extract the English and French sequences. Store them as a word-pair\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t', 2)[:-1]]  for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSNB7tnBNjQf",
        "outputId": "d39f3d50-78b3-489e-e0fa-0f3eb2eab2b7"
      },
      "source": [
        "# Check if the dataset has been created properly.\n",
        "\n",
        "%time en, fra = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(fra[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.32 s, sys: 245 ms, total: 9.57 s\n",
            "Wall time: 9.57 s\n",
            "<start> it may be impossible to get a completely error free corpus due to the nature of this kind of collaborative effort . however , if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning , we might be able to minimize errors . <end>\n",
            "<start> il est peut etre impossible d obtenir un corpus completement denue de fautes , etant donnee la nature de ce type d entreprise collaborative . cependant , si nous encourageons les membres a produire des phrases dans leurs propres langues plutot que d experimenter dans les langues qu ils apprennent , nous pourrions etre en mesure de reduire les erreurs . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVetNCNdNz-P"
      },
      "source": [
        "Now tokenize the sequences. Tokenization is the mechanism of creating an internal vocabulary comprising English and French tokens (i.e. words), converting the tokens (or, in general, sequences) to integers, and padding them all to make the sequences possess the same length. All in all, tokenization facilitates the model training process.\n",
        "\n",
        "Create a function tokenize() to encapsulate all the above-mentioned requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs5tBlAGN1hT"
      },
      "source": [
        "# Тоже стнадартно\n",
        "import tensorflow as tf\n",
        "\n",
        "# Convert sequences to tokenizers\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  \n",
        "  # Convert sequences into internal vocab\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  # Convert internal vocab to numbers\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  # Pad the tensors to assign equal length to all the sequences\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  # обрезает по длине максимально длинного предложения в корпусе текста\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jUr-OAeOO2y"
      },
      "source": [
        "#Load the tokenized dataset by calling the create_dataset() and tokenize() functions.\n",
        "\n",
        "# Load the dataset\n",
        "def load_dataset(path, num_examples=None):\n",
        " \n",
        "  # Create dataset (targ_lan = English, inp_lang = French)\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  # Tokenize the sequences\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0QNy2F1OZhA",
        "outputId": "cd972a71-f4b3-4626-86ec-020fa8383bd9"
      },
      "source": [
        "# Reduce the number of data samples required to train the model. Employing the whole dataset will consume a lot more time for training the model.\n",
        "\n",
        "# Consider 50k examples\n",
        "num_examples = 50000\n",
        "%time input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "# тоже более простой способ определения max_length_targ, max_length_inp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.2 s, sys: 138 ms, total: 4.34 s\n",
            "Wall time: 4.31 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjfQ-GBPOuI5",
        "outputId": "9dc36373-6069-4320-be68-b5272b288b26"
      },
      "source": [
        "print(max_length_targ, max_length_inp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqSndvY8O20E"
      },
      "source": [
        "#Step 4: Create the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZoQcJe5O0sa",
        "outputId": "1b6b72b1-e897-4e12-e7c0-e6c80f528dfe"
      },
      "source": [
        "# Segregate the train and validation datasets.\n",
        "\n",
        "#!pip3 install sklearn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create training and validation sets using an 80/20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000 40000 10000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGvNvz91PBGp",
        "outputId": "864453ea-2370-4d39-b580-b37fb2a8c929"
      },
      "source": [
        "#Validate the mapping that’s been created between the tokens of the sequences and the indices.\n",
        "\n",
        "# Show the mapping b/w word index and language tokenizer\n",
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t != 0:\n",
        "      try:\n",
        "        el_seq = lang.index_word[t]\n",
        "        print (\"%d ----> %s\" % (t, el_seq)) # lang.index_word[t]))\n",
        "      except:\n",
        "        print (\"There is no word whith index '%05i' in the dictionary \" % (t ))\n",
        "      \n",
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "81 ----> on\n",
            "68 ----> se\n",
            "1329 ----> voit\n",
            "271 ----> demain\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "4 ----> i\n",
            "37 ----> ll\n",
            "80 ----> see\n",
            "5 ----> you\n",
            "277 ----> tomorrow\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNa1ROcOPJw7",
        "outputId": "c2b33155-d8c0-486b-8e55-15fc73a46306"
      },
      "source": [
        "# проверим на отсутсвующие слова\n",
        "#convert(targ_lang, '<start> по русски <end>')\n",
        "print(target_tensor_train[0])\n",
        "#convert(targ_lang, np.array([1, 100000, 2])) #'<start> faisons <end>')\n",
        "convert(targ_lang, [1, 100000, 2]) \n",
        "# подправим на отсуствующие слова"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  1   4  37  80   5 277   3   2   0   0   0]\n",
            "1 ----> <start>\n",
            "There is no word whith index '100000' in the dictionary \n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w2KhwxMRXcH"
      },
      "source": [
        "#Step 5: Initialize the Model Parameters\n",
        "With the dataset in hand, start initializing the model parameters.\n",
        "\n",
        "- BUFFER_SIZE: Total number of input/target samples. In our model, it’s 40,000.\n",
        "- BATCH_SIZE: Length of the training batch.\n",
        "- steps_per_epoch: The number of steps per epoch. Computed by dividing - BUFFER_SIZE by BATCH_SIZE.\n",
        "- embedding_dim: Number of nodes in the embedding layer.\n",
        "- units: Hidden units in the network.\n",
        "- vocab_inp_size: Length of the input (French) vocabulary.\n",
        "- vocab_tar_size: Length of the output (English) vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrDBj5P1Rgn8"
      },
      "source": [
        "# Essential model parameters\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index) + 1\n",
        "vocab_tar_size = len(targ_lang.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN1ITWl4ScaM"
      },
      "source": [
        "#Next, call the tf.data.Dataset API and create a proper dataset.\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j82KoZL_SijV",
        "outputId": "f065f8a5-3920-4cb0-969c-5ef1efb4ccdf"
      },
      "source": [
        "# Size of input and target batches\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 19]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puM8hB7kSm_W"
      },
      "source": [
        "#Step 6: Encoder Class\n",
        "The first step in creating an encoder-decoder sequence-to-sequence model (with an attention mechanism) is creating an encoder. For the application at hand, create an encoder with an embedding layer followed by a GRU (Gated Recurrent Unit) layer. The input goes through the embedding layer first and then into the GRU layer. The GRU layer outputs both the encoder network output and the hidden state.\n",
        "\n",
        "Enclose the model’s __init__() and call() methods in a class Encoder.\n",
        "\n",
        "In the method, __init__(), initializes the batch size and encoding units. Add an embedding layer that accepts vocab_size as the input dimension and embedding_dim as the output dimension. Also, add a GRU layer that accepts units (dimensionality of the output space) and the first hidden dimension.\n",
        "\n",
        "In the method call(), define the forward propagation that has to happen through the encoder network.\n",
        "\n",
        "Moreover, define a method initialize_hidden_state() to initialize the hidden state with the dimensions batch_size and units.\n",
        "\n",
        "Add the following code as part of your Encoder class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__sIm5HbSrc5"
      },
      "source": [
        "# Encoder class\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "\n",
        "    # Embed the vocab to a dense embedding \n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # GRU Layer\n",
        "    # glorot_uniform: Initializer for the recurrent_kernel weights matrix, \n",
        "    # used for the linear transformation of the recurrent state\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  # Encoder network comprises an Embedding layer followed by a GRU layer\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  # To initialize the hidden state\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_0RADipSzRZ",
        "outputId": "53ba8a6a-8834-40c1-acc3-de9682341cee"
      },
      "source": [
        "#Call the encoder class to check the shapes of the encoder output and hidden state.\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 19, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVbbQG5qS6uM"
      },
      "source": [
        "#Step 7: Attention Mechanism Class\n",
        "This step captures the attention mechanism.\n",
        "\n",
        "Compute the sum (or product) of the encoder’s outputs and decoder states.\n",
        "- Pass the generated output through a fully-connected network.\n",
        "- Apply softmax activation to the output. This gives the attention weights.\n",
        "- Create the context vector by computing the weighted sum of attention weights and encoder’s outputs.\n",
        "\n",
        "Everything thus far needs to be captured in a class BahdanauAttention. \n",
        "\n",
        "Bahdanau Attention is also called the “Additive Attention”, a Soft Attention technique. As this is additive attention, we do the sum of the encoder’s outputs and decoder hidden state (as mentioned in the first step).\n",
        "\n",
        "This class has to have __init__() and call() methods.\n",
        "\n",
        "In the __init__() method, initialize three Dense layers: one for the decoder state ('units' is the size), another for the encoder’s outputs ('units' is the size), and the other for the fully-connected network (one node).\n",
        "\n",
        "In the call() method, initialize the decoder state (s0) by taking the final encoder hidden state. \n",
        "- Pass the generated decoder hidden state through one dense layer. \n",
        "- Also, plug the encoder’s outputs through the other dense layer. \n",
        "- Add both the outputs, encase them in a tanh activation and plug them into the fully-connected layer. \n",
        "\n",
        "This fully-connected layer has one node; thus, the final output has the dimensions batch_size * max_length of the sequence * 1.\n",
        "\n",
        "Later, apply softmax on the output of the fully-connected network to generate the attention weights.\n",
        "\n",
        "Compute the context_vector by performing a weighted sum of the attention weights and the encoder’s outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGDJstJDT3NP"
      },
      "source": [
        "# Attention Mechanism\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_uA0FwhUBsv",
        "outputId": "ff84c3bd-f107-4bef-c546-dbd9921f18a9"
      },
      "source": [
        "#Validate the shapes of the attention weights and its output.\n",
        "\n",
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 19, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YVT7jFIUJVZ"
      },
      "source": [
        "sample_hidden here is the hidden state of the encoder, and sample_output denotes the encoder’s outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGT1tD_qUNDZ"
      },
      "source": [
        "#Step 8: Decoder Class\n",
        "This step encapsulates the decoding mechanism. The Decoder class has to have two methods: __init__() and call().\n",
        "\n",
        "In the __init__() method, initialize the batch size, decoder units, embedding dimension, GRU layer, and a Dense layer. Also, create an instance of the BahdanauAttention class.\n",
        "\n",
        "In the call() method:\n",
        "- Call the attention forward propagation and capture the context vector and attention weights.\n",
        "- Send the target token through an embedding layer.\n",
        "- Concatenate the embedded output and context vector.\n",
        "- Plug the output into the GRU layer and then into a fully-connected layer.\n",
        "\n",
        "Add the following code to define the Decoder class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_8bijXHUTpj"
      },
      "source": [
        "## Decoder class\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # Used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # x shape == (batch_size, 1)\n",
        "    # hidden shape == (batch_size, max_length)\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "\n",
        "    # context_vector shape == (batch_size, hidden_size)\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab_size)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbMlQqC7S5D2",
        "outputId": "a9d242d8-8608-4e21-9c54-d982e136cf9b"
      },
      "source": [
        "#Validate the decoder output shape.\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 5918)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLM_D8B4UnuG"
      },
      "source": [
        "#Step 9: Optimizer and Loss Functions\n",
        "Define the optimizer and loss functions.\n",
        "\n",
        "As the input sequences are being padded with zeros, nullify the loss when there’s a zero in the real value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klNgjPM-Uoo7"
      },
      "source": [
        "# Initialize optimizer and loss functions\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "# Loss function\n",
        "def loss_function(real, pred):\n",
        "\n",
        "  # Take care of the padding. Not all sequences are of equal length.\n",
        "  # If there's a '0' in the sequence, the loss is being nullified\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aypSF6V9Uun4"
      },
      "source": [
        "#Step 10: Train the Model\n",
        "Checkpoint your model’s weights during training. This helps in the automatic retrieval of the weights while evaluating the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjtL6Tw7UvZN"
      },
      "source": [
        "import os\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAkiknoIU1Kk"
      },
      "source": [
        "Next, define the training procedure. First, call the encoder class and procure the encoder outputs and final hidden state. Initialize the decoder input to have the <start> token spread across all the input sequences (indicated using the BATCH_SIZE). \n",
        "\n",
        "Use the teacher forcing technique to iterate over all decoder states by feeding the target as the next input. This loop continues until every token in the target sequence (English) is visited.\n",
        "\n",
        "Call the decoder class with decoder input, decoder hidden state, and encoder’s outputs. Procure the decoder output and hidden state. Compute the loss by comparing the real against the predicted value of the target. Fetch the target token and feed it to the next decoder state (concerning the successive target token). Also, make a note that the target decoder hidden state will be the next decoder hidden state.\n",
        "\n",
        "After the teacher forcing technique gets finished, compute the batch loss, and run the optimizer to update the model's variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og8xcgn7U8T7"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  # tf.GradientTape() -- record operations for automatic differentiation\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    # dec_hidden is used by attention, hence is the same enc_hidden\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    # <start> token is the initial decoder input\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "\n",
        "      # Pass enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      # Compute the loss\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # Use teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  # As this function is called per batch, compute the batch_loss\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  # Get the model's variables\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  # Compute the gradients\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  # Update the variables of the model/network\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flcNKohEVBby"
      },
      "source": [
        "Now initialize the actual training loop. Run your loop over a specified number of epochs. First, initialize the encoder hidden state using the method initialize_hidden_state(). Loop through the dataset one batch at a time (per epoch). Call the train_step() method per batch and compute the loss. Continue until all the epochs have been covered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljVdQspZVFTs",
        "outputId": "fa49f2ee-2088-4dc1-a767-64e3130f2795"
      },
      "source": [
        "import time\n",
        "\n",
        "EPOCHS = 30\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  # Initialize the hidden state\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  # Loop through the dataset\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "\n",
        "    # Call the train method\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "\n",
        "    # Compute the loss (per batch)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # Save (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  # Output the loss observed until that epoch\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  \n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.8492\n",
            "Epoch 1 Batch 100 Loss 2.1289\n",
            "Epoch 1 Batch 200 Loss 1.8440\n",
            "Epoch 1 Batch 300 Loss 1.7853\n",
            "Epoch 1 Batch 400 Loss 1.5270\n",
            "Epoch 1 Batch 500 Loss 1.5625\n",
            "Epoch 1 Batch 600 Loss 1.2629\n",
            "Epoch 1 Loss 1.8229\n",
            "Time taken for 1 epoch 144.36796307563782 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.3848\n",
            "Epoch 2 Batch 100 Loss 1.3468\n",
            "Epoch 2 Batch 200 Loss 1.0773\n",
            "Epoch 2 Batch 300 Loss 1.0205\n",
            "Epoch 2 Batch 400 Loss 0.9292\n",
            "Epoch 2 Batch 500 Loss 0.8865\n",
            "Epoch 2 Batch 600 Loss 0.8973\n",
            "Epoch 2 Loss 1.0452\n",
            "Time taken for 1 epoch 128.30960702896118 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.7059\n",
            "Epoch 3 Batch 100 Loss 0.6930\n",
            "Epoch 3 Batch 200 Loss 0.5542\n",
            "Epoch 3 Batch 300 Loss 0.6007\n",
            "Epoch 3 Batch 400 Loss 0.5907\n",
            "Epoch 3 Batch 500 Loss 0.7067\n",
            "Epoch 3 Batch 600 Loss 0.6093\n",
            "Epoch 3 Loss 0.6262\n",
            "Time taken for 1 epoch 127.52085089683533 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.4589\n",
            "Epoch 4 Batch 100 Loss 0.3567\n",
            "Epoch 4 Batch 200 Loss 0.3951\n",
            "Epoch 4 Batch 300 Loss 0.2587\n",
            "Epoch 4 Batch 400 Loss 0.3725\n",
            "Epoch 4 Batch 500 Loss 0.4858\n",
            "Epoch 4 Batch 600 Loss 0.3908\n",
            "Epoch 4 Loss 0.3926\n",
            "Time taken for 1 epoch 128.01284527778625 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.2816\n",
            "Epoch 5 Batch 100 Loss 0.2660\n",
            "Epoch 5 Batch 200 Loss 0.2344\n",
            "Epoch 5 Batch 300 Loss 0.2955\n",
            "Epoch 5 Batch 400 Loss 0.2598\n",
            "Epoch 5 Batch 500 Loss 0.3030\n",
            "Epoch 5 Batch 600 Loss 0.2635\n",
            "Epoch 5 Loss 0.2625\n",
            "Time taken for 1 epoch 127.60985589027405 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1768\n",
            "Epoch 6 Batch 100 Loss 0.2372\n",
            "Epoch 6 Batch 200 Loss 0.1695\n",
            "Epoch 6 Batch 300 Loss 0.1686\n",
            "Epoch 6 Batch 400 Loss 0.1534\n",
            "Epoch 6 Batch 500 Loss 0.1895\n",
            "Epoch 6 Batch 600 Loss 0.2815\n",
            "Epoch 6 Loss 0.1873\n",
            "Time taken for 1 epoch 128.38729095458984 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1247\n",
            "Epoch 7 Batch 100 Loss 0.1104\n",
            "Epoch 7 Batch 200 Loss 0.1314\n",
            "Epoch 7 Batch 300 Loss 0.1403\n",
            "Epoch 7 Batch 400 Loss 0.1458\n",
            "Epoch 7 Batch 500 Loss 0.1294\n",
            "Epoch 7 Batch 600 Loss 0.1341\n",
            "Epoch 7 Loss 0.1420\n",
            "Time taken for 1 epoch 128.1372585296631 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1133\n",
            "Epoch 8 Batch 100 Loss 0.0765\n",
            "Epoch 8 Batch 200 Loss 0.1219\n",
            "Epoch 8 Batch 300 Loss 0.1462\n",
            "Epoch 8 Batch 400 Loss 0.1220\n",
            "Epoch 8 Batch 500 Loss 0.1029\n",
            "Epoch 8 Batch 600 Loss 0.1213\n",
            "Epoch 8 Loss 0.1156\n",
            "Time taken for 1 epoch 128.75131225585938 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0859\n",
            "Epoch 9 Batch 100 Loss 0.0748\n",
            "Epoch 9 Batch 200 Loss 0.1056\n",
            "Epoch 9 Batch 300 Loss 0.1309\n",
            "Epoch 9 Batch 400 Loss 0.0949\n",
            "Epoch 9 Batch 500 Loss 0.0863\n",
            "Epoch 9 Batch 600 Loss 0.1486\n",
            "Epoch 9 Loss 0.0997\n",
            "Time taken for 1 epoch 127.65864586830139 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0600\n",
            "Epoch 10 Batch 100 Loss 0.0653\n",
            "Epoch 10 Batch 200 Loss 0.0733\n",
            "Epoch 10 Batch 300 Loss 0.1094\n",
            "Epoch 10 Batch 400 Loss 0.0754\n",
            "Epoch 10 Batch 500 Loss 0.0845\n",
            "Epoch 10 Batch 600 Loss 0.0770\n",
            "Epoch 10 Loss 0.0883\n",
            "Time taken for 1 epoch 128.48457026481628 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.0682\n",
            "Epoch 11 Batch 100 Loss 0.0605\n",
            "Epoch 11 Batch 200 Loss 0.0739\n",
            "Epoch 11 Batch 300 Loss 0.0555\n",
            "Epoch 11 Batch 400 Loss 0.0754\n",
            "Epoch 11 Batch 500 Loss 0.0858\n",
            "Epoch 11 Batch 600 Loss 0.1034\n",
            "Epoch 11 Loss 0.0819\n",
            "Time taken for 1 epoch 127.44990086555481 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.0721\n",
            "Epoch 12 Batch 100 Loss 0.0751\n",
            "Epoch 12 Batch 200 Loss 0.0784\n",
            "Epoch 12 Batch 300 Loss 0.0637\n",
            "Epoch 12 Batch 400 Loss 0.0612\n",
            "Epoch 12 Batch 500 Loss 0.1022\n",
            "Epoch 12 Batch 600 Loss 0.0859\n",
            "Epoch 12 Loss 0.0759\n",
            "Time taken for 1 epoch 127.85005593299866 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.0523\n",
            "Epoch 13 Batch 100 Loss 0.0626\n",
            "Epoch 13 Batch 200 Loss 0.0800\n",
            "Epoch 13 Batch 300 Loss 0.0701\n",
            "Epoch 13 Batch 400 Loss 0.0724\n",
            "Epoch 13 Batch 500 Loss 0.0705\n",
            "Epoch 13 Batch 600 Loss 0.0729\n",
            "Epoch 13 Loss 0.0714\n",
            "Time taken for 1 epoch 127.49929118156433 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.0243\n",
            "Epoch 14 Batch 100 Loss 0.0614\n",
            "Epoch 14 Batch 200 Loss 0.0497\n",
            "Epoch 14 Batch 300 Loss 0.0888\n",
            "Epoch 14 Batch 400 Loss 0.0609\n",
            "Epoch 14 Batch 500 Loss 0.0720\n",
            "Epoch 14 Batch 600 Loss 0.0543\n",
            "Epoch 14 Loss 0.0684\n",
            "Time taken for 1 epoch 128.04587292671204 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.0539\n",
            "Epoch 15 Batch 100 Loss 0.0880\n",
            "Epoch 15 Batch 200 Loss 0.0297\n",
            "Epoch 15 Batch 300 Loss 0.0474\n",
            "Epoch 15 Batch 400 Loss 0.0865\n",
            "Epoch 15 Batch 500 Loss 0.0760\n",
            "Epoch 15 Batch 600 Loss 0.1132\n",
            "Epoch 15 Loss 0.0641\n",
            "Time taken for 1 epoch 127.27607893943787 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.0571\n",
            "Epoch 16 Batch 100 Loss 0.1063\n",
            "Epoch 16 Batch 200 Loss 0.0686\n",
            "Epoch 16 Batch 300 Loss 0.0600\n",
            "Epoch 16 Batch 400 Loss 0.0761\n",
            "Epoch 16 Batch 500 Loss 0.0660\n",
            "Epoch 16 Batch 600 Loss 0.0705\n",
            "Epoch 16 Loss 0.0618\n",
            "Time taken for 1 epoch 128.20140647888184 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.0354\n",
            "Epoch 17 Batch 100 Loss 0.0560\n",
            "Epoch 17 Batch 200 Loss 0.0234\n",
            "Epoch 17 Batch 300 Loss 0.0870\n",
            "Epoch 17 Batch 400 Loss 0.0441\n",
            "Epoch 17 Batch 500 Loss 0.0546\n",
            "Epoch 17 Batch 600 Loss 0.0545\n",
            "Epoch 17 Loss 0.0595\n",
            "Time taken for 1 epoch 127.41766905784607 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.0297\n",
            "Epoch 18 Batch 100 Loss 0.0598\n",
            "Epoch 18 Batch 200 Loss 0.0571\n",
            "Epoch 18 Batch 300 Loss 0.0378\n",
            "Epoch 18 Batch 400 Loss 0.0883\n",
            "Epoch 18 Batch 500 Loss 0.0711\n",
            "Epoch 18 Batch 600 Loss 0.0549\n",
            "Epoch 18 Loss 0.0587\n",
            "Time taken for 1 epoch 127.85002326965332 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0666\n",
            "Epoch 19 Batch 100 Loss 0.0382\n",
            "Epoch 19 Batch 200 Loss 0.0381\n",
            "Epoch 19 Batch 300 Loss 0.0386\n",
            "Epoch 19 Batch 400 Loss 0.0527\n",
            "Epoch 19 Batch 500 Loss 0.0595\n",
            "Epoch 19 Batch 600 Loss 0.0685\n",
            "Epoch 19 Loss 0.0575\n",
            "Time taken for 1 epoch 127.15791201591492 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0425\n",
            "Epoch 20 Batch 100 Loss 0.0775\n",
            "Epoch 20 Batch 200 Loss 0.0469\n",
            "Epoch 20 Batch 300 Loss 0.0655\n",
            "Epoch 20 Batch 400 Loss 0.0633\n",
            "Epoch 20 Batch 500 Loss 0.0593\n",
            "Epoch 20 Batch 600 Loss 0.0623\n",
            "Epoch 20 Loss 0.0538\n",
            "Time taken for 1 epoch 127.51484107971191 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.0603\n",
            "Epoch 21 Batch 100 Loss 0.0662\n",
            "Epoch 21 Batch 200 Loss 0.0392\n",
            "Epoch 21 Batch 300 Loss 0.0335\n",
            "Epoch 21 Batch 400 Loss 0.0494\n",
            "Epoch 21 Batch 500 Loss 0.0557\n",
            "Epoch 21 Batch 600 Loss 0.0651\n",
            "Epoch 21 Loss 0.0523\n",
            "Time taken for 1 epoch 126.97018361091614 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.0273\n",
            "Epoch 22 Batch 100 Loss 0.0453\n",
            "Epoch 22 Batch 200 Loss 0.0493\n",
            "Epoch 22 Batch 300 Loss 0.0508\n",
            "Epoch 22 Batch 400 Loss 0.0404\n",
            "Epoch 22 Batch 500 Loss 0.0498\n",
            "Epoch 22 Batch 600 Loss 0.0613\n",
            "Epoch 22 Loss 0.0518\n",
            "Time taken for 1 epoch 128.29395699501038 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.0513\n",
            "Epoch 23 Batch 100 Loss 0.0295\n",
            "Epoch 23 Batch 200 Loss 0.0457\n",
            "Epoch 23 Batch 300 Loss 0.0531\n",
            "Epoch 23 Batch 400 Loss 0.0361\n",
            "Epoch 23 Batch 500 Loss 0.0440\n",
            "Epoch 23 Batch 600 Loss 0.0746\n",
            "Epoch 23 Loss 0.0488\n",
            "Time taken for 1 epoch 126.6783139705658 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.0264\n",
            "Epoch 24 Batch 100 Loss 0.0416\n",
            "Epoch 24 Batch 200 Loss 0.0484\n",
            "Epoch 24 Batch 300 Loss 0.0627\n",
            "Epoch 24 Batch 400 Loss 0.0465\n",
            "Epoch 24 Batch 500 Loss 0.0507\n",
            "Epoch 24 Batch 600 Loss 0.1050\n",
            "Epoch 24 Loss 0.0489\n",
            "Time taken for 1 epoch 127.37876582145691 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.0426\n",
            "Epoch 25 Batch 100 Loss 0.0455\n",
            "Epoch 25 Batch 200 Loss 0.0303\n",
            "Epoch 25 Batch 300 Loss 0.0516\n",
            "Epoch 25 Batch 400 Loss 0.0459\n",
            "Epoch 25 Batch 500 Loss 0.0455\n",
            "Epoch 25 Batch 600 Loss 0.0677\n",
            "Epoch 25 Loss 0.0484\n",
            "Time taken for 1 epoch 128.0638391971588 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss 0.0423\n",
            "Epoch 26 Batch 100 Loss 0.0452\n",
            "Epoch 26 Batch 200 Loss 0.0558\n",
            "Epoch 26 Batch 300 Loss 0.0491\n",
            "Epoch 26 Batch 400 Loss 0.0670\n",
            "Epoch 26 Batch 500 Loss 0.0368\n",
            "Epoch 26 Batch 600 Loss 0.0387\n",
            "Epoch 26 Loss 0.0474\n",
            "Time taken for 1 epoch 128.23332905769348 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss 0.0308\n",
            "Epoch 27 Batch 100 Loss 0.0331\n",
            "Epoch 27 Batch 200 Loss 0.0464\n",
            "Epoch 27 Batch 300 Loss 0.0227\n",
            "Epoch 27 Batch 400 Loss 0.0360\n",
            "Epoch 27 Batch 500 Loss 0.0578\n",
            "Epoch 27 Batch 600 Loss 0.0962\n",
            "Epoch 27 Loss 0.0457\n",
            "Time taken for 1 epoch 127.90302562713623 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss 0.0287\n",
            "Epoch 28 Batch 100 Loss 0.0181\n",
            "Epoch 28 Batch 200 Loss 0.0677\n",
            "Epoch 28 Batch 300 Loss 0.0503\n",
            "Epoch 28 Batch 400 Loss 0.0594\n",
            "Epoch 28 Batch 500 Loss 0.0677\n",
            "Epoch 28 Batch 600 Loss 0.0404\n",
            "Epoch 28 Loss 0.0457\n",
            "Time taken for 1 epoch 128.28263449668884 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss 0.0503\n",
            "Epoch 29 Batch 100 Loss 0.0416\n",
            "Epoch 29 Batch 200 Loss 0.0253\n",
            "Epoch 29 Batch 300 Loss 0.0390\n",
            "Epoch 29 Batch 400 Loss 0.0921\n",
            "Epoch 29 Batch 500 Loss 0.0398\n",
            "Epoch 29 Batch 600 Loss 0.0383\n",
            "Epoch 29 Loss 0.0445\n",
            "Time taken for 1 epoch 127.62137794494629 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 0.0490\n",
            "Epoch 30 Batch 100 Loss 0.0405\n",
            "Epoch 30 Batch 200 Loss 0.0374\n",
            "Epoch 30 Batch 300 Loss 0.0281\n",
            "Epoch 30 Batch 400 Loss 0.0532\n",
            "Epoch 30 Batch 500 Loss 0.0238\n",
            "Epoch 30 Batch 600 Loss 0.0922\n",
            "Epoch 30 Loss 0.0430\n",
            "Time taken for 1 epoch 128.1065616607666 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yXYiV_mVuf8"
      },
      "source": [
        "#Step 11: Test the Model\n",
        "Now define your model evaluation procedure. First, take the sentence given by the user into consideration. This has to be given in the French language. The model now has to convert the sentence from French to English.\n",
        "\n",
        "Initialize an empty attention plot to be plotted later on with max_length_target on the Y-axis, and max_length_input on the X-axis.\n",
        "\n",
        "Preprocess the sentence and convert it into tensors.\n",
        "\n",
        "Then plug the sentence into the model.\n",
        "\n",
        "Initialize an empty hidden state which is to be used while initializing an encoder. Usually, the initialize_hidden_state() method in the encoder class gives the hidden state having the dimensions batch_size * hidden_units. Now, as the batch size is \n",
        "1\n",
        ", the initial hidden state has to be manually initialized.\n",
        "\n",
        "Call the encoder class and procure the encoder outputs and final hidden state.\n",
        "\n",
        "By looping over max_length_targ, call the decoder class wherein the dec_input is the <start> token, dec_hidden state is the encoder hidden state, and enc_out is the encoder’s outputs. Procure the decoder output, hidden state, and attention weights.\n",
        "\n",
        "Create a plot using the attention weights. Fetch the predicted token with the maximum attention. Append the token to the result and continue until the <end> token is reached.\n",
        "\n",
        "The next decoder input will be the previously predicted index (concerning the token).\n",
        "\n",
        "Add the following code as part of the evaluate() function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MzqOvjTV063"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Evaluate function -- similar to the training loop\n",
        "def evaluate(sentence):\n",
        "\n",
        "  # Attention plot (to be plotted later on) -- initialized with max_lengths of both target and input\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  # Preprocess the sentence given\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # Fetch the indices concerning the words in the sentence and pad the sequence\n",
        "  #inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  # подпрвиv, чтобы не выскакивала ошибка на незнакомое слово\n",
        "  \n",
        "  inputs = []\n",
        "  for i in sentence.split(' '):\n",
        "    try:\n",
        "      ind_inp = inp_lang.word_index[i]\n",
        "      inputs.append(ind_inp)\n",
        "    except KeyError:\n",
        "      #ind_inp = 100000\n",
        "      #print( f\"В словаре нет слова '{i}'\")\n",
        "      print (\"There is no word '%s' in the dictionary \" % (i ))\n",
        "    \n",
        "  \n",
        "\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  # Convert the inputs to tensors\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  # Loop until the max_length is reached for the target lang (ENGLISH)\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # Store the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    # Get the prediction with the maximum attention\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    # Append the token to the result\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    # If <end> token is reached, return the result, input, and attention plot\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # The predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrHlXExaV4Iq"
      },
      "source": [
        "#Step 12: Plot and Predict\n",
        "Define the plot_attention() function to plot the attention statistics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEzxiHKNV7MZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "# Function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXtuePdlV_sK"
      },
      "source": [
        "#Define a function translate() which internally calls the evaluate() function.\n",
        "\n",
        "# Translate function (which internally calls the evaluate function)\n",
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz7zlOGMWI_Y",
        "outputId": "b6e6a39b-8e58-4036-af62-dd32fc67edf9"
      },
      "source": [
        "# Restore the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f90d01acfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "QEEOdAGSWMPe",
        "outputId": "71cfffc8-0001-48c1-db32-cf2fded22479"
      },
      "source": [
        "#Call the translate() function by inputting a few sentences in French.\n",
        "\n",
        "translate(u\"As tu lu ce livre?\")\n",
        "# The actual translation is \"Have you read this book?\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> as tu lu ce livre ? <end>\n",
            "Predicted translation: did you read that book ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "iOsQcutUma7q",
        "outputId": "bc06331e-21a3-4698-c862-d5d48b7ef09e"
      },
      "source": [
        "# Проверим с отсутсвующим словом\n",
        "translate(u\"As tu lu ce livre? Вас тут не стояло\")\n",
        "# The actual translation is \"Have you read this book?\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There is no word 'вас' in the dictionary \n",
            "There is no word 'тут' in the dictionary \n",
            "There is no word 'не' in the dictionary \n",
            "There is no word 'стояло' in the dictionary \n",
            "Input: <start> as tu lu ce livre ? вас тут не стояло <end>\n",
            "Predicted translation: did you read that book ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAHFCAYAAACU1Q+8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debhkVX3u8e9LdwMCgrMgEXEAFTUYxIErKopDNMYE9ZqrwQmvGKOiUW8SNSoah5hgFCWJ4AAqRFETr+YSjSNRiUoQB1AECYMQRMAJmqHH3/1j74NFeXo6nlO7avX38zz99Kld+1S91Ryq3rP22munqpAkSdJs22boAJIkSfr1WeokSZIaYKmTJElqgKVOkiSpAZY6SZKkBljqJEmSGmCpkyRJaoClTpIkqQGWOkmSpAZY6iRJkhpgqVsiSfZK8oUk9xk6iyRJap+lbuk8EzgIOGzgHJIkaSuQqho6Q3OSBLgI+Czwu8AdqmrdoKEkSVLTHKlbGgcBNweOANYCjxs0jSRJap4jdUsgyQnA6qo6PMlbgTtV1ZMHjiVJ0tRL8ghgH6CA71XVFweONDMsdYssyY7Aj4DfqaovJ7kv8FVgt6r6+bDpJEmaTkl2Bz4O3A+4rN98B+AM4JCqumxD36uOh18X35OAq6rqywBV9S3gB8D/GjSVJEnT7R3AOuBuVXXHqrojsFe/7R2DJttMSXZM8owkuwzx/Ja6xfd04MSxbScCz5p8FEmSZsajgBdU1YVzG6rqArr56Y8aLNWWeQpwPF0XmDhL3SJKckfg4cAHx+76R2D/JHtPPpUkSTNjvjlhszRP7BnAuQw0kOOcOkmSNLgkHwduCzy1qi7pt+0BnARcWVVPHDLfpiTZEzgPeADwNWC/qvreJDM4UrfIkuzRr1M3732TziNJ0ow4AtgRuCDJxUkuBv6r33bEoMk2z9OBL/dz6f+V7iIEE+VI3SJLso7uTNcrxrbfGriiqpYNk0ySpOnWD4o8ErhHv+mcqvrcgJE2W5IfAG+sqhOSPAk4GrhjTbBoWeoWWZL1wO2r6sqx7XeiW29nx2GSSZKkpZDkfwCfAXatqpVJtgUuB/6gqj47qRzLJ/VErUsyd7p1AW9Oct3I3cvojrF/a+LBJEmaASOfo/Oqqmk+BPtM4BNVtRKgqlYn+QjdCROWuhl0n/7vAPcEVo/ctxo4Ezhq0qEkSZoRL6RbrH/1PPdN7WHFJNvRLWXy1LG7TgT+LclOc2VvybN4+HXx9HMBPgIcVlXXDJ1HkqRZ0U9f2nV8Tvq0S3Ibumu8n1hV68fuOxT4XFVdPpEslrrFk2QZcAOw76RPY5YkaZb1JxruOj4nXZvPw6+LqKrW9adgbzt0FkmSZkyAE5OsBK6lu/7rN4FTJnX4ctY5UrfIkjyT7rj6oVV11dB5JEmaBUlO6L9cAewC3IFujvrPgYOn7QhYkgvZzLl+VXWXJY4DWOoWXZKzgDvT/VBeSvfbxo2q6jeHyCVJ0qxJcnPgQwBV9fiB49xEkpeN3NwJeClwOt3JHgAH0K188daqev0kMnn4dfF9bOgAkiS1oKquSfJy4C+HzjKuqt4693U/yviWqnrT6D5JXgHca1KZHKmTJEn6NSS5mu5ar+ePbb8bcGZV7TyJHI7USZKkwSV5zUburqqautG6EdcCBwHnj20/CLhufOel4kjdIusvDfIqupMl9qCbW3cjr/0qSdKv6tepOxdY22+6B3AB3WLENc1z0pP8Kd0h4uOBr/WbH0R3pYkjq+otE8lhqVtcSd4C/AHwZuBtwF8AewL/C3h1VR07XDpJkqbT+OLDSa6hW/f1gmGTbZ4kTwFeTHfGLsA5wNFV9ZGJZbDULa7+FOfnV9Wn+x/I+1bVfyV5Pt0p2U8eOKK0VUtye+DpwF3pftG6KsmDgcuq6sJh00lbryRrgDtV1WX97euAP66qEwYNNkO2GTpAg24PzK2lsxK4Rf/1p4FHD5JIEgBJ7kd3eOcPgecAc5OXHwW8cahckgC4hO7/RZI8hG4x4jcl+eskM9NXktwiya1G/0zquWfmH2mG/JBuwUToJkw+pv/6AOD6QRJJmnMU3eGQ3wJWjWz/N+DBw0SS1DsOeF+S84HPAe8G9gcOBD47ZLBNSXKnJJ9Kcj3wE+DK/s9V/d8T4dmvi+/jwMF0EyWPBj6U5LnA7sDfDBlMEvejG6Eb9yO6UXZJA6mqv0pyJrAvcCHwT1VVSR5G93k6zY6nOzL3HLrLmw0yt805dUssyQPpRgDOq6r/N3QeaWuW5MfA46rqG6OTsJP8NnBcVe0xcERNiSR7AJeUH5LaDP31ah9UVWcPmcORukWW5KHAf1TVWoCq+jrw9STLkzy0qr40bEJpq/YJ4LVJ/md/u5LsCbwF+KehQmkqXQjsBlwxdJCtTZJHAPvQjXZ9r6q+OHCkzXEhsN3QIRypW2RJ1gG7zZ2SPbL91sAVrlMnDSfJzsC/Ar8J7AhcTnfY9TS6EbxrN/LtWoAkLwR+XlUnjm0/FNi5qv5+mGQbN768hpZekt3ppjDdj+4QJnRz1M8ADpk7K3Ya9UX0z+nO1h1fgHhyOSx1i6t/I7h9VV05tn1v4IxJXSpE0q9KsgPdQqYPBfajO1nszKr63KDBGtZPen9OVf372PYDgeOraq9hkm3cht7LtXSS/BNdiXva3PJCSe4CnEi35NDULgnWT+fYDlhGdxLW2tH7vUzYjEnyyf7LAk5MMnpm3TLg3sB/TDyYJACSLAN+QTeP7gvAFwaOtLX4DeDiebZf2t83zS5PMu8dHnVZEo8CDhpdL7Kf83oE8PnhYm2WFw4dACx1i+kn/d8BfsZNly9ZDXyF7vRsSQOoqnVJLga2HTrLVuZy4L7ARWPb96Nb7mGaPRn46dAhtjLzHT6c+kOKVfX+oTOApW7RVNWzAZJcBBzl3BxpKv0l8FdJDq2qaS8UrfhH4B1JrgVO7bc9HHg7cNJQoTZDAac5p26iPg+8M8lTq+oSuPEs5Lcz/SN1U3G1GufULbK5Va+ran1/e1fg8XRn8Hj4VRpQkrOAOwMr6A7/3eSXr2m+YPisSrIC+ADdNbHX9Zu3AT4KPL2q1gyVbWM8UWLyktwR+CTddKXREyXOAp5QVZcOlW1T+qvVfJ7uLNh7AffoDx0fCexdVU+bSA5L3eJK8ing01V1dJKdgO/TnWW3E91k4Q8MGlDaiiV57cbur6rXTSrL1ibJXnSHYQG+VVU/GDLPpvQL3p42tzyVJiPdJMZHAvfoN50zCycyJfki8KWqeu3YGpgHAB+uqjtNJIelbnEluRJ4RFWdleQZdKc470t3rcmXzspIQJKb0S2a/IOqmm+Ss7ZiSbanG4G+K3BsVf08yV2Bn1WVc5A085J8C3gPcFJV/WzoPFsqyR8DL6Abmb53XzD+HLigqj4ybLr59Z+ZJ1fVqk3uPGWSXA3ct/93Hi11ewLfr6rtJ5HDa78uvp2An/dfPxr4eH944Qt0H4BTKckJ/ZsASbYFTgc+A5yb5LGDhtNUSXI34BzgXcAbgbmLVT8f+Ouhcm2OJP83yZP6n3FNSJK9k7wyybuSvG/0z9DZNuIU4E+By5J8KMnBQwfaXEleAvwF3bVUR0/f/W+m5CzNDTge2GXoEAt0PXDLebbfgwkuYG2pW3w/BB6cZEfgMfzyIsS3Aq4bLNWmPYbuerUATwBuDuwKHNn/mUpJ9tvYn6HzNertdD/Xt+emZ3l/km4C/DS7Dng/8OMk7+kPsWkJJfkd4DvA7wKHAXcHHgccAtxmwGgbVVWvAu4EPJFuWapTklyY5DX95P1p9kfAc6vqaG66XtqZdPO9ptX868fMhrmr1cxdVWKQq9V4+HWRJXkecAywkm5tpv2qan2/zs7vV9UjBg24AUluAO5WVZcmeQ/wi6p6Wf9DeVZV3XzQgBvQT2YubvpmcOMPtWtJLb4kP6W7xuF58xxmOKeqbjZowE3of+E6BHga3dydHwEfAk4c+rqNLUryDeBjVfXmuZ8XuknwHwS+WlV/O2jAzZTkVsDzgNfSrRzxeeBtVfXpQYPNI8n1dBP1Lx77f3RvuvmMOwwccV79+/khdMuC/YppvszmRq5W8x/AYye1IoZLmiyyqjo2yRnAHsBn586CBf4LePVwyTbpcuDeSX5EN2p3eL99J2Aqz07r3Xns9grgt4BXAa+YfJytxop5tu1Bt7jvVOvfXE+kWyT8tnRnZf4R8HJ8T1wKdwdO7r9eA+xQVTckeT3dIc6pL3VJHkQ3yvgHdIX0eLrrwn4syXuq6iVD5pvHBXTrAI7Ph34c8L3Jx9kiH9/A9qIbMZ1KVXU1cGB/ubDBrlbjG9giSrIL8JtV9WXgG2N3/5zp/p/pfXRvvJfRLTswtybQA+nO4J1KGziJ4/wkv6D7jfpTE4602UauQjKvqnrCpLJsoc8ALwWe09+u/rfU19F9SM+E/mSPR9D9ErM3cMmwiZp1DTA3SfxHwN2As+k+f+abgzQVktwOeAbwbLr50J8EnlxVnx3Z54N0UxGmrdQdBRzTXxYvwAFJnk43R/CwQZNt2swtIzP62T9+tZp+nbrvTepkG0vd4loPfCrJY6rqtLmNSfal+4+8+2DJNqGqXp/ku3SjLR+tqtX9XWvp5gTMmgv55fIJ0+onY7dX0B2auiPwz5OPs9leCnwxybl0H9Yn031QXwE8Zchgm9Ivl/AourPRf5/uF5iPAgf3v4xp8X0dOJDul9pTgLf274mHAF8dMtgmXAqcD7wXeP8GFqv+LvCfE021Garq+CTLgTcBO9Ad6r4MOKKqTt7oNw9rVueDTc1nv3PqFlmSk4CVVfW8kW1H0S0+OK0jLwD0bwIPoCt2Nzk7cFrX1+vnudxkE91hkSOBu1TVzJ0skeStwNXTvGZav+TNUxk5zEC39MP1G/3GgSW5HNiZbgT3ROCUkV9gtATSXZB9p6r6Tj9y9Fa65ZLOo1vm6YeDBtyAJOuAW1fVzze58xRLchtgm1kY/ZrlBZ+n5bPfUrfIkjyGbtL1rlW1ur/CxKXAC6tqakdfktyD7vDCXeiK0Tq6kdw1wKqq2nnAeBs0cqLETTbTHUr7g6r62q9+13TrJzN/papuN3SW+SR5I3BJVb1rbPsfAbtX1dTOHU3yXLqR6Jn+oJ41SZZV1br+69sADwXOrarvDptsw2a8YFzIRka9quouE4yz2ZK8CfjhjL63TMVnv0uaLL7P0i3z8Pj+9sF0o17/MliizfN2utGWXeiWfbgnsD/wLeBJA+balGfTHU57RP/nIGAfYC9+eZmZWXP3oQNswtOBb86z/Uy6OUhTq6rePWuFLsnjk7wk3SUHZ06SJwJXJ7msX+vtHOAjwLf7eV7TbFZHPY4B/g74e7rLbH24vz33Z1odyvzvLd9gyt9bmJLPfkfqlkCStwB3r6rfT/IB4JqqesHQuTYmyU+Ah1XV2f1JBg+oqnP7dbzeOa1XwugPkew2/tt0klsDV0zzkiZJ3jG+ie7Q8WOB91XViyafatP65W/2qaoLxrbfhW5C8ERWTt9c/Qkph1bV1bN2ckq6KwD8Jd18xeXAI6vqrGFTbZl019v9CvBj4AjgHcDr6eZmPruqpnLdtH6k7mRuuhbjjapq2k84AGB0SZOhs2zKrL23jJuGz35PlFgaHwC+0S9QeQhdY5924ZeLI19JN7HzXLrh47sNFWozhPl/m94JuGHCWbbUfcZur6f7t/8TurORp9UPgYfQLZsw6qF0Py/T5if88mfkp8zW6Msf018zOskrgc+mu5TS9+lGom8LrJjWeWm9vehGLy4FXkl3Gaj1SU6mK6zTLMz2grizZtbeW8YN/tlvqVsCVfXdJGcDJwGXVtXpQ2faDGfTnXl5Ad0lwv6sHwV7Lt0ZYFNlZJSrgDcnGb1axzK6Ez6+NfFgW6Cqpv3qCxtyLPC2dJfamjt1/2DgzUzhmdJV9eyRr581YJSFuBXwJYCqelM/T2dumZ77073H7M0Ur99Fdwjquqpal2QVv/xlazVjJ2RNmaI7W3Tm5tTNsJl6bxk3DZ/9lrql8wG6eWqvGjrIZnoj3SrY0F0z8BTgi8BVTOcyFXOjXKGb/zd6BuNquvldR0061KZs6vDfqGk7FDinqt7aT3Z/B7/8UF4NHF1VU3ft1y34N6+q+r0lDbPlzqObI3oRQFW9Icl76Q7Tn0M3z2gqrw4wZu4Xr22BI/spHtOee2ZH6MamdmxLd/mqGxcGr6ojJp9q02btvWUDBv3sd07dEumX2ngRcGxVXT50noXoX8PPaop/SJIcD7y4X8176vV5N8voCNM06i+3tU9/85yqWjlkng2Z5X/zJC8EHl5V03yy0kYlOZWNn4k5lSPW/c/NEVV1zdBZtlSSL27k7qopvVzlnFl5b5nP0J/9ljpJkqQGuKSJJElSAyx1kiRJDbDULaEkhw+dYaFmNfus5obZzT6ruWF2s89qbpjd7LOaG2Y3+6zmhuGyW+qW1sz+QDK72Wc1N8xu9lnNDbObfVZzw+xmn9XcMLvZZzU3DJTdUidJktSArf7s122zXW1/4/Jsi2sNq1jBdkvy2EttVrPPam6Y3exLmjtLu1TYmrqBFVmqKw8t3XvrmlrFiizNv3m3vvHSWV03sO1S/ZsvX7o1mFevu55tl91sSR577U5Luwbz2huuZfn2S/M5t2z1+iV5XIDVa65l2xVLkztrli43wOp117HtsqVZivHqVZdfVVW3ne++rX7x4e3ZkQdmFq7iJf0alrgcLZVsO80XHNiEdeuGTrAg2W72frGYs81tbjV0hAX56YN3HzrCgu30w2m/GuP8Vlwxc8sP3ujfzn3LxRu6z8OvkiRJDbDUSZIkNcBSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDbDUSZIkNcBSJ0mS1ABLnSRJUgNmptQl+X9JTui/PjXJMZvY/+wkR04imyRJ0tCWDx1ggZ4IrBk6hCRJ0rSYyVJXVT8dOoMkSdI0mcrDr0l2SHJCkpVJfpzklWP33+Twa5LbJflEkuuTXJzksMmnliRJGs5UljrgKOBRwJOAg4HfAh66kf1PAO4GPBL4feAZwJ5LmlCSJGmKTN3h1yQ7Ac8BDquqf+u3PRu4dAP77w08Fjiwqk7rtz0TuGAyiSVJkoY3jSN1dwW2Bb46t6GqVgJnbWD/ewLrgdNH9r8YuGxDT5Dk8CRnJDljDasWJbQkSdKQprHULVRt9o5Vx1XV/lW1/wq2W8pMkiRJEzGNpe6/6JYredDchiQ7AvfewP7fp3sdDxjZfw/gDkuYUZIkaapM3Zy6qlqZ5L3AW5JcSXcY9TXAsg3sf26STwPHJjkcuB742/5vSZKkrcLUlbrey4EdgY8D1wHv7G9vyLOAdwNfAK4CXgfcbmkjSpIkTY+pLHVVdS3dsiTP2MD9B43d/jHwhLHd3rMk4SRJkqbQNM6pkyRJ0hay1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDbDUSZIkNcBSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDlg8dYHA73oy6775Dp9hi67af3f90lx687dARFuSuJ141dIQFqwsvGTrCgtS69UNHWLh97z50ggWps88fOsKCrb14Nn/Od57R3LNs3dABlogjdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDbDUSZIkNcBSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDRi81CV5RpKfJNlubPtJST7Zf/28JOcnWd3//dyxfSvJk8e2XZTk5Uv/CiRJkoY3eKkDPkqX4/fmNiTZBTgEeG+SQ4BjgLcD9waOBv4+ye8OkFWSJGkqLR86QFVdn+Qk4DDgI/3mpwFXA6cA/w58sKqO6e87L8n9gD8D/mUhz5nkcOBwgO232+XXSC9JkjQdpmGkDuDdwKOS/EZ/+zDg/VW1FrgncNrY/l8B9lnok1XVcVW1f1Xtv2L5jgt9GEmSpKkxFaWuqr4NnAk8K8m9gf2B923q28a+ztj9KxYvoSRJ0nSbilLXezfwLOB/A6dV1bn99nOAB4/teyDwvZHbVwK7zd1IcvvR25IkSa0bfE7diA8Bfws8H/ijke1/A3w0yTeAzwC/Dfwh8MSRfb4AvCDJfwDrgDcBN0witCRJ0jSYmpG6qrqG7kSJVfzyhAmq6v8CLwL+hG507sXAH1fV6EkSLwMuAE4FPga8B7hiIsElSZKmwDSN1EF3yPTkqrp2dGNVvQt414a+qaouAx47tvmfFj+eJEnSdJqKUpfklsBDgEcD+w4cR5IkaeZMRakDvgncCnhlVZ09dBhJkqRZMxWlrqr2HDqDJEnSLJuaEyUkSZK0cJY6SZKkBljqJEmSGmCpkyRJaoClTpIkqQGWOkmSpAZY6iRJkhpgqZMkSWqApU6SJKkBljpJkqQGWOokSZIaYKmTJElqgKVOkiSpAcuHDjC0rFnHih/9fOgYW2ybyy4fOsKC7bFmn6EjLMgPn3DboSMs2B4fXz90hAXZZs3aoSMs2NoVy4aOsCDLb3XLoSMs2NofXzl0hIVZv27oBGqEI3WSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDbDUSZIkNcBSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDWi21CVZmeRZQ+eQJEmahGZLnSRJ0tZk0FKXZNshn1+SJKkVEy11SU5N8g9JjkpyJXBakn2SnJLkmiRXJPlQkl1Hvuf+ST6T5KokVyf5SpIDxh73bv1j35Dk3CSPn+TrkiRJGtoQI3WHAgEeAhwBfAk4G3gA8EhgJ+ATSeay3Rz4YL//A4BvAf+a5NYA/X4fp3stBwCHAUcC203m5UiSJA1v+QDPeWFVvQwgyeuBb1fVn83dmeQZwE+B/YHTq+oLo9+c5EXAk4DHAifSFcF9gDtX1Q/7fV4CfHkCr0WSJGkqDDFS942Rr+8HPLQ/U3VlkpXAJf19dwVIcrskxyY5L8kvgGuA2wF79PvdE/jvuULX+zqwfkMBkhye5IwkZ6xef90ivSxJkqThDDFSd+3I19sApwAvn2e/H/d/vx+4PfAnwEXAKuDzwIJPsqiq44DjAHbZbtda6ONIkiRNiyFK3agzgacAF1fVmg3scyBwRFWdApDk9sBuI/efA+ye5I5VNTfK9wBcrkWSJG1Fhi4+fwfsApyc5IFJ7pLkkUmOS3Lzfp/zgEP7s2TvD3wYWD3yGJ8Dvg98IMl9+zNj3wasneDrkCRJGtSgpa6qLgMeTDf/7dPAd+mK3qr+D3Rns+5ENxfvw8D76A7Dzj3GeuAQutfydeADwBtGvl+SJKl5Ez38WlUHzbPtB8CTN/I93wYeOLb5g2P7nAc8bGyfnRaWUpIkafYMffhVkiRJi8BSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDbDUSZIkNcBSJ0mS1ABLnSRJUgMsdZIkSQ1YPnSAodXq1ay9+NKhY2y59euGTrBg23z5m0NHWJDb7Hz/oSMs2Hmv3XnoCAty53+ooSMs2DanfXvoCAuybr99ho6wcD+6fOgE0qAcqZMkSWqApU6SJKkBljpJkqQGWOokSZIaYKmTJElqgKVOkiSpAZY6SZKkBljqJEmSGmCpkyRJaoClTpIkqQGWOkmSpAZY6iRJkhpgqZMkSWqApU6SJKkBljpJkqQGWOokSZIaYKmTJElqgKVOkiSpAVNT6pIclKSS3GboLJIkSbNmsFKX5NQkx8zK40qSJE2zqRmpkyRJ0sINUuqSnAA8DHhBf8i1gD37u/dN8vUk1yU5I8l+I9936yQfSnJpkuuTfDfJszf2uEnmHleSJKlZQ43UvRj4KnA8sFv/55L+vjcDfw7sB/wEOClJ+vu2B84EHg/cCzgaODbJwZvxuJIkSc1aPsSTVtUvkqwGrquqywGS3KO/+9VV9cV+2+uBrwC7A5dW1X8DfzPyUMcleQTwVODz8z3ufJIcDhwOsD07LPKrkyRJmrxpnFP3nZGvL+v/vh1AkmVJXpXkO0l+kmQl8ERgjy15gqo6rqr2r6r9V7Dd4qSWJEka0CAjdZuwZuTr6v+eK58vB15Gd5j1LGAl8Cb60idJkrS1GrLUrQaWbeH3HAj8S1V9EKCfa7c38PNf83ElSZJm2pCHXy8CHpBkz37B4c3Jch5wcJID+zl4xwB33tjjJpnGQ8ySJEmLasjCcxTdqNr3gCvZvHlxbwBOBz4FfAm4FjhpER5XkiRppg12+LWqzgMOGNt8wtg+FwEZuf0zuhMjtvRxJUmSmuahSUmSpAZY6iRJkhpgqZMkSWqApU6SJKkBljpJkqQGWOokSZIaYKmTJElqgKVOkiSpAZY6SZKkBljqJEmSGmCpkyRJaoClTpIkqQGWOkmSpAZY6iRJkhpgqZMkSWqApU6SJKkBy4cOMBXWrxs6gWbA9p/7ztARFmyvz2foCAty6Yv2GzrCgu3+9RVDR1iQc5+3w9ARFmyv4/cdOsKC5KvfHjqCGuFInSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDbDUSZIkNcBSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDlrzUJTk1yTFL/BwXJXn5Uj6HJEnSNHOkTpIkqQGWOkmSpAZMqtQtT3J0kp/1f/4myTYASW6Z5P399uuTfC7JvUa/OckTk5yVZFWSS5K8Kkk29GRJDk1ydZInLPULkyRJmgaTKnV/2D/XAcDzgMOBl/T3nQA8EGegMGsAAApcSURBVPg94AHAdcCnk9wMIMn9gI8C/wzcB/hz4BXAC+d7oiQvBt4JPL6qPrk0L0eSJGm6LJ/Q8/wIOKKqCvh+kr2Blyb5F+AJwMOq6ksASZ4O/JCuCL4HeCnw71X12v6xzkuyF/BndOXtRkn+kq4wPqKqvjmB1yVJkjQVJjVS97W+0M35KrA7cE9gfX8bgKr6BXAWsE+/6Z7AaWOP9xVg9yQ7j2x7MfAi4MBNFbokhyc5I8kZa1i1kNcjSZI0Vab5RIna9C432ecr/e2nbvKbqo6rqv2rav8VbLfQfJIkSVNjUqXugWMnNjwIuAw4h1/OtQOgH327D/C9ftM5wIPHHu9A4NKqumZk2zeAR9Md1n314saXJEmabpMqdXcA3p7k7kmeDPwf4G1V9QPgE8CxSR6S5D7AicDVwD/23/tW4GFJjkyyd5I/BF4G/PX4k1TVf9IVu5cl+Yulf1mSJEnTYVInSpwELAO+TneI9L3A2/r7ng28HfgksD3d/LnfrqrrAarqzCT/E3gd8Ergx8BfAfNepaKqTk/yaOAzSaiqNyzZq5IkSZoSS17qquqgkZu/sgxJVf0MeOYmHuOf6ZY02dD9e47dPh24xZbklCRJmmXTfKKEJEmSNpOlTpIkqQGWOkmSpAZY6iRJkhpgqZMkSWqApU6SJKkBljpJkqQGWOokSZIaYKmTJElqgKVOkiSpAZY6SZKkBljqJEmSGmCpkyRJaoClTpIkqQGWOkmSpAZY6iRJkhqwfOgA0qyoVauGjrBgtc2yoSMsyG/83beGjrBg69esHjrCgtzjmGuGjrBgn/r0h4eOsCCPucN9h46gRjhSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDbDUSZIkNcBSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNaKrUJXlhkm8muTbJJUleMXQmSZKkSVg+dIBFdjDwGuC7wEOB9yT5blV9cthYkiRJS6upUldVh4zcvCDJm4C7DZVHkiRpUpo6/DoqySuBFcCHh84iSZK01JoaqZuT5C+AI4BHVdVl89x/OHA4wPbsMOF0kiRJi6+5UpfkDsDrgd+pqm/Nt09VHQccB7BzblUTjCdJkrQkWjz8uhsQ4Jyhg0iSJE1Ki6XuHOD+wK8cdpUkSWpVi6Xu3sCJwG2HDiJJkjQpLZa6HYC70535KkmStFVo7kSJqjqVbk6dJEnSVqPFkTpJkqStjqVOkiSpAZY6SZKkBljqJEmSGmCpkyRJaoClTpIkqQGWOkmSpAZY6iRJkhpgqZMkSWqApU6SJKkBljpJkqQGWOokSZIaYKmTJElqgKVOkiSpAZY6SZKkBljqJEmSGrB86ADSrMjy2f3fJTe72dARFmSW/825YdXQCRYkq9YOHWHBzll93dARFmabZUMnWLj164ZOoBGO1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDbDUSZIkNcBSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1YGZKXZKXJ7lo6BySJEnTaGZKnSRJkjZsUUpdkp2T3GIxHmsLnvO2Sbaf5HNKkiRNqwWXuiTLkjwmyT8ClwP79tt3SXJckiuSXJPk35PsP/J9z0qyMsnBSc5Ocm2SLya589jj/2mSy/t9PwDsNBbhccDl/XM9eKGvQ5IkqQVbXOqS3CvJXwOXACcD1wK/DXwpSYBTgN2BxwO/BXwJ+EKS3UYeZjvgFcBhwAHALYB3jTzHU4A3AK8F9gPOBV46FuUk4GnAzYHPJjk/yWvGy6EkSdLWYLNKXZJbJzkiyTeAbwL3AF4M7FpVz62qL1VVAQ8H7gs8uapOr6rzq+rVwAXA00cecjnwgn6f7wBHAQf1pRDgJcD7q+rYqjqvqt4InD6aqarWVtW/VtVTgV2BN/XP/4MkpyY5LMn46J4kSVKTNnek7kXA0cANwN5V9YSq+mhV3TC23/2AHYAr+8OmK5OsBO4N3HVkv1VVde7I7cuAbYFb9rfvCXx17LHHb9+oqq6uqvdV1cOB+wO3B94LPHm+/ZMcnuSMJGesYdVGXrYkSdJsWL6Z+x0HrAGeAZyd5OPAB4HPV9W6kf22AX4MPGSex7h65Ou1Y/fVyPdvsSTb0R3uPZRurt136Ub7PjHf/lV1HN1rYufcqubbR5IkaZZsVomqqsuq6o1VdXfgkcBK4MPApUnemuS+/a5n0o2Sre8PvY7+uWILcp0DPGhs201up3NgkmPpTtR4J3A+cL+q2q+qjq6qn23Bc0qSJM2sLR4Zq6qvVdXzgd3oDsvuDfxnkocAnwNOAz6R5LFJ7pzkgCSv6+/fXEcDz0zy3CR7JXkF8MCxfQ4FPgPsDDwVuGNV/Z+qOntLX5MkSdKs29zDr7+iqlYBHwM+luR2wLqqqiSPoztz9d3A7egOx54GfGALHvvkJHcB3kg3R++TwN8CzxrZ7fN0J2pc/auPIEmStHVZcKkbNXpotaquoTsz9sUb2PcE4ISxbacCGdv2ZuDNY99+5Mj9ly08sSRJUlu8TJgkSVIDLHWSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDbDUSZIkNcBSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1wFInSZLUgOVDB5BmRa1dO3SEBatrrhk6gmbEunPPHzrCgr1kz/8xdIQFWjd0ADXCkTpJkqQGWOokSZIaYKmTJElqgKVOkiSpAZY6SZKkBljqJEmSGmCpkyRJaoClTpIkqQGWOkmSpAZY6iRJkhpgqZMkSWqApU6SJKkBljpJkqQGWOokSZIaYKmTJElqgKVOkiSpAZY6SZKkBljqJEmSGmCpkyRJaoClTpIkqQGWOkmSpAZY6iRJkhpgqZMkSWrA8qEDDCHJ4cDhANuzw8BpJEmSfn1b5UhdVR1XVftX1f4r2G7oOJIkSb+2rbLUSZIktcZSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDbDUSZIkNcBSJ0mS1ABLnSRJUgMsdZIkSQ2w1EmSJDXAUidJktQAS50kSVIDLHWSJEkNsNRJkiQ1IFU1dIZBJbkSuHiJHv42wFVL9NhLbVazz2pumN3ss5obZjf7rOaG2c0+q7lhdrPPam5Y2ux3qqrbznfHVl/qllKSM6pq/6FzLMSsZp/V3DC72Wc1N8xu9lnNDbObfVZzw+xmn9XcMFx2D79KkiQ1wFInSZLUAEvd0jpu6AC/hlnNPqu5YXazz2pumN3ss5obZjf7rOaG2c0+q7lhoOzOqZMkSWqAI3WSJEkNsNRJkiQ1wFInSZLUAEudJElSAyx1kiRJDfj/DyJ0PTC72ecAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "AEVcy6JUWbUX",
        "outputId": "333b0e33-0091-4d4c-b45f-2837c6016c66"
      },
      "source": [
        "translate(u\"Comment as-tu été?\")\n",
        "# The actual translation is \"How have you been?\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> comment as tu ete ? <end>\n",
            "Predicted translation: how did you been ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAJ6CAYAAACCOI5qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dedzv93zn/+crOVlEJCghqF1a+3bsy0RjqWXMWIbatxGUoq3qqKma3xSDtKSjcyN2ZVrL1ESZQVRCbZNGpBVCRGwRREqRRdbX74/P93C5cp3IuXLO9Xl/z7nfb7frdq7v5/O9rut1fcT5Ps7n+1mquwMAwPx2m3sAAAAmwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMKMpVZVF1XVAWss/5WqumiOmQBgvYQZy662snyvJOdv5CAAcHltmnsAWI+q+r3Fp53k6VV11orVuye5R5IvbfhgAHA5lJuYs4yq6muLT6+X5LQkK9+2PD/J15O8qLv/3waPBgDrJsxYalV1dJKHdvcP554FAC4vYQYAMAjHmLH0quqRSQ5JckBWndDS3Q+eZSgAWAdhxlKrqlcmeW6So5OcnulkAABYSt7KZKlV1feSPLO73zP3LABwebmOGctutyQnzD0EAGwPwoxld0SSx849BABsD44xY9ldOcmjq+o+Sf45yQUrV3b3s2eZCgDWQZgNqKpukuR1SZ7T3Z+fe57B3Sw/fyvz11etcwAlAEtFmI3pCUkOTvLkJL877yhj6+57zT0DAGwvzsocTFVVptsJHZXk3ya5VndfdKlfRKrqaklulOSE7j5v7nkAYD0c/D+eg5NcKcmzk1yY5AGzTjO4qrpSVb07yRlJPpXk2ovlr62qF885GwBsK2E2nickeU93n5PkbxaP2bqXJ7lWktslOXfF8vcnecgsEwHAOjnGbCBVdcUkD03ywMWiv0ry6aq6cnf/63yTDe3BSR7S3SdU1cr35U9KcsOZZgKAdbHHbCwPS3Jmd/9DknT3CUm+kuS3Zp1qbFdJ8i9rLL9SEsfmAeyCquqKVfX4qtp/7lm2lTAby+OSvH3VsrcneeLGj7I0/jHTXrMttuw1e1qmY84A2PU8IsmbM72uLhVnZQ6iqn41ydeS3LS7v7Ji+XUynaV5s+4+eabxhlVVd03yoUzH4z02yRuS3DzJHZPcs7uPn3E8AGZQVUcnuUaSc7p789zzbAthxtKrqlsmeV6S22faC3x8kpe7OC/Arqeqrp/k5Ez/QP9Mktt19xfnnGlbCLOBVNV1k3yr1/gfpaqu293fnGEsAFgaVfXHSQ7u7kOq6m+TfKW7/3DuuS4rYTaQqrooyYHdfcaq5b+S5Izu3n2eycZXVVdNckBWHTe5TP9KAuDyq6qvJHlJd7+lqh6W5PAkv7rWTo8ROfh/LJW17++4b5KfbvAsS6GqbltVJyT5fpIvJDkxyedX/AnALmJx3PGBSd6zWPR3SfZJcu/ZhtpGrmM2gKr6i8WnneRlVXXOitW7Z3qf/IRLfCFJ8qYk307ynCTfixuXA+zKnpDkyO4+K0m6+/yqelemqxscNedgl5UwG8MtF39WkpsmOX/FuvMzHcx+2EYPtSRukuQ/dPcpcw8CwHyqaq9Ml8l41KpVb0/yoarad0uwjUyYDaC777W4efm7kjy5u38y90xL5BOZYlaYAezarpTp3ZMPr1zY3Z+oqqdlOixo+DBz8P8gqmr3TMeR3doB65ddVV0707XLPpjpuLILVq7v7o/PMRcArIc9ZoPo7ouq6htJ9px7liVzkyS3TXK/NdZ1pmP0AGAp2GM2kKp6Qqb3xh/b3WfOPc8yqKovZ7ot08uyxsH/3b3WfTQB2ElU1ddyGU/86u4b7uBxLjd7zMbyvCQ3SPLtqjotydkrV3b3rWaZamzXSfKA7v7q3IMAMIvXrPh83yS/l+TYJJ9eLLtLpqsb/NkGz7Uuwmws7/nlT2GVozLdikmYAeyCuvtnwVVVb8l0S76XrnxOVb0g032Uh+etTJZaVT09yQuTvDXTBWVXH/z/t3PMBcDGq6ofZ7o35imrlt84yfHdvd88k1129pix7P7H4s8/WmOdg/8Bdi1nJzk4l7yE0sFJzln95BEJs4FU1Z6Z9v48Ksl1k+yxcr17ZV5Sd7utGABbvCrJX1bV5iSfWSy7c6Y7Arx4rqG2hTAby39N8shMZxi+KskfJLl+kt9K8sfzjQUA4+vuV1TV1zNdaPYRi8UnJXlCd79rtsG2gWPMBrI45fcZ3f3BqvpJktt091er6hlJDunuh8884pCq6rZJ7pXkgCS/sAetu58/y1AAsA72mI3lGkm2XPX/rCRXXnz+wSQvn2WiwVXV85P8tyTfyCWvY+ZfHQC7qKq6ci75j/UfzDTOZSbMxvLNJNda/HlKpqvZfzbTNVjOnXGukf1upr2Mr5t7EADmVVXXS/LaTAf7r7yTTmVJTggTZmN5b5JDMh2weHiSv66qpya5dpJXzjnYwHZL8vdzDwHAEN6c6d2mpyQ5PUv4zoljzAZWVXdKcrckJ3f3++eeZ0RV9eIke3T3C+eeBYB5VdVZSe7c3SfOPct6CbOBVNU9k3yquy9ctXxTkrt298fnmWxcVVVJ/k+SayY5MZe8wOyT55gLgI1XVZ9P8sTu/uzcs6yXa0CN5egkV11j+f6LdVzSS5LcN8mFSa6S5OqrPgDYdTwnycsWV/pfSvaYDaSqLk5yje7+/qrlByU5bhluJbHRqupfkzytu9859yzA2qrqt5M8M8kNktyiu0+tqv+U5NRlubYUy2Fxqam9Mh3kf16mf7T/zDK8jjr4fwBV9b7Fp53k7VV13orVuye5RZJPbfhgy+HcJJ+bewhgbVX13CTPz3TJn/+2YtW3kzwriTBje3rW3ANcXsJsDP+y+LOS/DC/eGmM85N8IsnrN3qoJfGqJM+tqme23b8woqcneWp3f6Cq/nTF8uOT3HymmdhJdfdb557h8hJmA+juJyXJ4jYSh3X32fNOtFTukeSeSR5YVV/MJQ/+f/AsUwFbXC/TiTmrXZDkChs8C7uAqrpGkscluVGSP+7uM6vqbklO7+6vzTvdLyfMxvJfVz6oqmsmeVCSL3a3tzLXdmaSv517CGCrTk1yu0x351jpAfn5nU5gu6iq22e6tuXXMu2RfWWm14n7JDkoyaPnm+6yEWZj+UCm2y8dXlX7JjkuyRWT7FtVT+nut8063YC27G0EhnVYktdU1T6ZDte4S1U9LtNxZy5nw/Z2WJLDu/tPFicCbPGhJEvxeiHMxrI5019WSfLQJD/OdBbTY5I8L4kw24qqumGSm2U6geKk7j515pGWSlVdIdPFjL/S3av3bMC6dfebF9difGmSfZL8VaYrsj/b2dTsALfPdNX/1b6T6X7Uw3Mds7Hsm+RfF5/fN8l7u/uCJB/N9F45q1TVflX17kz3Fv3fSY5M8pWqeldVXWne6cZVVW9ZXMIgVbVnkmOTfDjJl6vq/rMOx06nu1/f3ddLckCSa3b3dbr7jXPPxU7p3EzXtFzt15OcscGzrIswG8s3k9ytqq6Y6QbmRy2WXzXJObNNNbbDk9wqyb0yHUh8hUz3G71VklfPONfo7pfpnqxJ8uAkV8p094QXLz5Ypapud2kfc883qqr6aFVdOUm6+8zuPmOxfL+q+ui807ETOjLJn1TVXovHXVXXz3S5lv8111DbwgVmB1JVT0vymiRnZTpQ9nbdfXFVPTvJv+/u35h1wAFV1b9k2jb/sGr5PTPtcfyVeSYbW1X9NMmNu/u0qnpDkh919+8v/gL7fHfb27jK4gLQnek4qS1+9hdod+++4UMtgcV2u+aWIFux/IAk3+7uPeaZjJ1RVe2X6TZ9t8p0jPZ3M72F+akk91+Gqx44xmwg3f26qjouyXWTHNXdFy9WfTXJH8832dCukJ9fB26lHyTZe4NnWSbfTXKLqvpOpr1nhy6W75tVlxzhZ26w6vEeSW6b5IVJXrDx44xt1V7EW1XVD1Y83j3Tf3ff3tip2Nl194+T3L2qfiPT2cC7JTm+uz8y72SXnT1mg6iq/ZPcavWen8W6u2W6ZMYPN36ysVXVUZlOknhcd5+zWHbFTCdK7Nfd95lzvlFV1YuS/H6mg7CvkOSg7j6/qp6S5CndfddZB1wiVXXfJH/S3Xebe5aRrNjDmPziXsYtzk3yO939po2bip3ZzvI6KswGsThQ/TtJ7tfdn1yx/NaZDsy+dnefOdd8o6qqW2a6xMg+Sf55sfiWmf7Sv293f2Gu2UZXVQ/LtHf23d192mLZE5L8a3cfOetwS6SqbpLkhO6+4tyzjKSqrpcpyE5NcsckK+8BfH6SM7r7ojlmY+e0s7yOCrOBVNU7kpzV3U9bseywTHszXMF+KxbXR3pMprNukuSkJO/o7nO3/lUsLmFwx0xxtufKda6Zd0lVddXVi5IcmOlkiRt2txMAtmJxpu8zk9ww04vmt6rqPyb5Wnf//bzTsTPZGV5HhdlAqup+Sf4604Gy51fVbklOS/Ks7nZ1+zVU1UuSfKu7X7tq+dMz/evIsXlrqKpfT/K+TC+UleSiTMecXpDkvO7eb8bxhrTqrbmfLU7yrSSP7O7PXPKrqKrHJHltkjdkum/mzbv71MXJTg/t7vvNOiA7lZ3hddTlMsZyVKa34B60eHxIpj0ZfzfbRON7XJLPrbH8+CSP3+BZlsmrM22j/TNdiuWmmS5wfEKSh80418ielOm2Lr+x+Dg400WNb5LpWD3W9vxMNzH/3SQXrlj+mSS3mWeksVXVg6rquYvb8rFtlv51VJgNZHEW5tvz86B4XJJ3Li4yy9oOyC8eu7LFmVmSqzzP5A5J/nRx6vjFSTZ19/GZXkT/bNbJxvWmJCd298cWH//Q3V/KdA244W+MPKObJPn0GsvPSmLP7CpV9Z+SvDfJHyT5p8VxtFxGO8PrqDAbz9uS/GZVXTfJQ5K8deZ5RvfNJPdYY/k9M+2+Zm2Vn1+0+PtJrr34/LQkN55lovFVLvlWZjJdYuSnGzzLMjk9082jV7tnpksB8Yt+O9OZ0dfOdAHto6rqvlV13araVFUHLl4f2Lqlfh11HbPBdPcXqurEJO9Iclp3Hzv3TIN7XZJXLW4rtOUq4ockeVmmKz2zthOT3DrTGXPHJvnDqrooyVMz3d6Khar6i8WnneRlVbXyLhy7ZzqB4oQNH2x5HJHkLxYH+yfJr1bVPZK8Iu4ysZarJvl4knT3SxfHSP3fxbo7ZHptOCjTf3usYdlfR4XZmN6W6RigF849yOi6+8+q6mpJ/iI/P7Pw/CSHd/cr5ptseC/JdFXsJPnPST6Q5OhMbwE/Yq6hBrXlraTKdCze+SvWnZ/pWL3DNnqoZdHdr1hcX+qoTBd9PjrJeUkO6+6/nHW4MZ2c6djFrydJd/9pVb0x0xnAJ2V6i26f2aZbHkv7OuqszAEtTsv/nSSv6+7vzj3PMlhcVPZmi4cndfdZc86zjBb/3f2w/aWwpqp6c5LnLK4szjZaXNbmZpkOofmi/4+uraqeleRe3e0knMthmV9HhRkAwCAc/A8AMAhhNrCqOvSXP4vVbLdtZ5utj+22PrbbtrPN1mcZt5swG9vS/Qc1CNtt29lm62O7rY/ttu1ss/VZuu0mzAAABrHLH/y/Z+3dV9ht37nHWNP5/dPsWXvPPcaa+uKL5x5hqy7Iedkje809xlKxzdbHdlsf223b2WbrM/J2+0l+eGZ3X3318l3+OmZX2G3f3HmfB/3yJ/ILLj777LlHAC7Nbq4/us0uvmjuCZZT1dwTLKWPXPzub6y13FuZAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIOYJcyq6piqes0cPxsAYFT2mAEADEKYAQAMYs4w262qXlpVZ1bVGVV1WFXtliRVdZWqemtV/bCqzq2qj1TVzbd8YVV9p6p+a8XjT1TVT6pq0+Lxjauqq+o6G/9rAQCsz5xh9pgkFya5a5JnJXlukkcu1r0lyZ2S/Lskd0xyTpIPVtUVFus/luTgJKmqfZLcIcl5STYv1h+c5KvdfdoO/h0AALabOcPsi939ou4+ubvfleToJIdU1U2SPDjJod398e7+fJLHJdkvU8wlyTFJ7rX4/K5JTk3y/hXLDl48Z01VdWhVHVdVx53fP92+vxUAwDrNGWb/vOrx6UkOSHLTJBcn+fSWFd39oySfT3KzxaJjkhxUVQdmirCjF8sOXqz/N7mUMOvuI7p7c3dv3rP2vny/BQDAdjJnmF2w6nHnl8/TSdLdX0ry3Ux7yA7Oz8PsblV10yTXyaWEGQDAiEY8K/OkTHPdZcuCqtovyS2TfHHF8z6W5IGZjis7pru/nuTMJM+P48sAgCU0XJh191eSHJnkdVV1j6q6ZZK3J/lxkv+54qnHJHlEklO6+/srlj029pYBAEtouDBbeFKSY5O8b/HnPkl+s7vPXfGcY5Jsyi9G2FrLAACWQnX33DPMav/dr9Z33udBc4+xdC4+++y5RwAuzW67zz3B8rn4orknWE5Vc0+wlD5y8bs/292bVy8fdY8ZAMAuR5gBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMYtPcA8xu0+7Z7WpXnXuKpdMHXX/uEZbOT6+5z9wjLKVN51409whL6fu33nvuEZbOgZ/6ydwjLKXdvvyNuUdYTj9ae7E9ZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAg1iaMKuq91fVWxafH1NVr/klzz+xql68EbMBAGwPm+YeYJ0emuSCuYcAANieljLMuvsHc88AALC9DflWZlXtU1Vvqaqzqup7VfVHq9b/wluZVXVAVR1ZVedW1Teq6skbPzUAwOUzZJglOSzJfZI8LMkhSW6b5J6X8vy3JLlxknsn+fdJHp/k+lt7clUdWlXHVdVx51907nYaGQDg8hnurcyq2jfJU5I8ubs/tFj2pCSnbeX5ByW5f5K7d/cnF8uekOTUrf2M7j4iyRFJsv9e1+jt+gsAAKzTiHvMbpRkzySf3rKgu89K8vmtPP+mSS5OcuyK538jyek7cEYAgO1uxDBbL3u+AIClNmKYfTXTpTDuvGVBVV0xyS228vwvZfo97rji+ddNcq0dOCMAwHY33DFm3X1WVb0xycur6vuZ3pJ8UZLdt/L8L1fVB5O8rqoOTXJukj9f/AkAsDSGC7OF5yW5YpL3JjknyX9fPN6aJyZ5fZKPJjkzyX9JcsCOHREAYPsaMsy6++xMl7x4/FbWH7zq8feSPHjV096wQ4YDANhBRjzGDABglyTMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAaxae4B5ldJ1dxDLJ368tfmHmHp7J0bzD3CUjr9N/afe4SldMXvXDz3CEunzr9w7hGW0zWuNvcEy+lHay+2xwwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBCzh1lVPb6q/qWq9lq1/B1V9b7F50+rqlOq6vzFn09d9dyuqoevWvb1qnrejv8NAAC2j9nDLMm7M83x77YsqKr9kzwkyRur6iFJXpPk1UlukeTwJP+jqv7tDLMCAOwwm+YeoLvPrap3JHlyknctFj86yY+TfCDJx5L8VXe/ZrHu5Kq6fZI/TPJ36/mZVXVokkOTZO/dr3Q5pgcA2H5G2GOWJK9Pcp+qus7i8ZOTvLW7L0xy0ySfXPX8TyS52Xp/WHcf0d2bu3vznrvvs95vAwCwXQ0RZt39T0mOT/LEqrpFks1J3vTLvmzV57Vq/R7bb0IAgB1viDBbeH2SJyb5j0k+2d1fXiw/KcndVj337km+uOLx95McuOVBVV1j5WMAgGUw+zFmK/x1kj9P8owkT1+x/JVJ3l1Vn03y4SS/meQxSR664jkfTfLMqvpUkouSvDTJTzdiaACA7WWYPWbd/ZNMB/+fl5+fBJDu/t9JfifJ72baS/acJL/d3SsP/P/9JKcmOSbJe5K8IckZGzI4AMB2MtIes2R6+/Gd3X32yoXd/dokr93aF3X36Unuv2rx/9r+4wEA7DhDhFlVXSXJPZLcN8mtZx4HAGAWQ4RZks8luWqSP+ruE+ceBgBgDkOEWXdff+4ZAADmNszB/wAAuzphBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMIhNcw8wu4svTp997txTLJ2Lzzln7hGWzm4nf33uEZbSdb6+59wjLKUvvfoGc4+wdK7yuQvnHmEp/ei2B8w9wnI6ee3F9pgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxih4ZZVR1TVa/ZkT8DAGBnYY8ZAMAghBkAwCA2Isw2VdXhVfXDxccrq2q3JKmqPavq5VV1WlWdU1X/WFX3W/nFVXWzqvpAVf2kqs6oqr+uqmuuWP+Wqnp/VT2nqr69+Blvrqp9NuB3AwDYbjYizB6z+Dl3SfK0JIcmee5i3ZuT/Jskj05yiyRvTfJ3VXXrJKmqA5N8PMmJSe6Y5N5J9k1y5Ja4W7jH4uvvneSRSR6S5Dk79LcCANjONm3Az/hOkmd3dyf5UlUdlOT3qurIJI9Kcv3u/ubiua+pqntnCrjfTvKMJP/U3X+45ZtV1eOT/CDJ5iTHLhb/OMnTu/uiJCdV1buTHJLkZWsNVFWHZgrE7L3bvtv1lwUAWK+N2GP2mUWUbfHpJNdOcvckleSLVXXWlo8kD0xyo8Vzb5/knqvWf2ux7kYrvucXF1G2xelJDtjaQN19RHdv7u7Ne+52hcv32wEAbCcbscfs0nSSOyS5YNXycxd/7pbkA0met8bXfm/F56u/vuPEBgBgyWxEmN2pqmrFXrM7Z9qj9elMe8yu2d1Hb+Vrj0/yiCTf6O7V8QUAsFPZiL1K10ry6qr6tap6eJI/SPKq7j45yTuSvKWqHl5VN6yqzVX1vKp66OJr/zLJ/kneWVV3Wjzn3lV1RFVdaQNmBwDYMBuxx+wdSXZP8v8yvcX4xiSvWqx7UpIXJnlFkutkOqj/2CRHJ0l3n15Vd8t0EP8Hk+yd5JtJPpzkvA2YHQBgw+zQMOvug1c8fNYa6y9I8uLFx9a+x1eSPPxS1j9xjWWX+j0BAEbkAHkAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEFUd889w6z2q6v2neqQuccAYG5Vc0+wlD707c/NPcJS2v3AUz7b3ZtXL7fHDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQO1WYVdWzqupzVXV2VX2rql4w90wAAJfVprkH2M4OSfKiJF9Ics8kb6iqL3T3++YdCwDgl9upwqy7H7Li4alV9dIkN55rHgCAbbFThdlKVfVHSfZI8jdrrDs0yaFJsnf22eDJAADWtlMdY7ZFVf3nJM9Ncp/uPn31+u4+ors3d/fmPbLXxg8IALCGnW6PWVVdK8n/l+SB3X3C3PMAAFxWO+MeswOTVJKT5h4EAGBb7IxhdlKSOyS5xFuYAAAj2xnD7BZJ3p7k6nMPAgCwLXbGMNsnya9lOiMTAI2/vWsAAAd2SURBVGBp7HQH/3f3MZmOMQMAWCo74x4zAIClJMwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABiHMAAAGIcwAAAYhzAAABrFp7gEAYAjdc0+wlO53rdvMPcKSOmXNpfaYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMYmnCrKqeV1Vfn3sOAIAdZWnCDABgZ7ddwqyq9quqK2+P77UNP/PqVbX3Rv5MAIAdad1hVlW7V9X9qup/Jvluklsvlu9fVUdU1RlV9ZOq+lhVbV7xdU+sqrOq6pCqOrGqzq6qo6vqBqu+//Or6ruL574tyb6rRnhAku8uftbd1vt7AACMYpvDrKpuXlWvSPKtJO9McnaS30zy8aqqJB9Icu0kD0py2yQfT/LRqjpwxbfZK8kLkjw5yV2SXDnJa1f8jEck+dMkf5Lkdkm+nOT3Vo3yjiSPTnKlJEdV1SlV9aLVgQcAsCwuU5hV1a9U1bOr6rNJPpfk15M8J8k1u/up3f3x7u4k90pymyQP7+5ju/uU7v7jJKcmedyKb7kpyTMXz/nnJIclOXgRdkny3CRv7e7XdffJ3f2SJMeunKm7L+zu/9Pdj0pyzSQvXfz8r1TVMVX15KpavZdty+9zaFUdV1XHXZDzLssmAADY4S7rHrPfSXJ4kp8mOai7H9zd7+7un6563u2T7JPk+4u3IM+qqrOS3CLJjVY877zu/vKKx6cn2TPJVRaPb5rk06u+9+rHP9PdP+7uN3X3vZLcIck1krwxycO38vwjuntzd2/eI3tdyq8NALBxNl3G5x2R5IIkj09yYlW9N8lfJfn77r5oxfN2S/K9JPdY43v8eMXnF65a1yu+fptV1V6Z3jp9bKZjz76Qaa/bkev5fgAAc7hMIdTdp3f3S7r715LcO8lZSf4myWlV9WdVdZvFU4/PtLfq4sXbmCs/ztiGuU5KcudVy37hcU3uXlWvy3TywX9PckqS23f37br78O7+4Tb8TACAWW3zHqru/kx3PyPJgZne4jwoyT9W1T2SfCTJJ5McWVX3r6obVNVdquq/LNZfVocneUJVPbWqblJVL0hyp1XPeWySDyfZL8mjkvxqd/9Bd5+4rb8TAMAILutbmZfQ3ecleU+S91TVAUku6u6uqgdkOqPy9UkOyPTW5ieTvG0bvvc7q+qGSV6S6Zi19yX58yRPXPG0v8908sGPL/kdAACWT00nU+669qur9p3qkLnHAAB2IR/p93y2uzevXu6WTAAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAg9g09wBzqKpDkxyaJHtnn5mnAQCY7JJ7zLr7iO7e3N2b98hec48DAJBkFw0zAIARCTMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBVHfPPcOsqur7Sb4x9xxbcbUkZ849xBKy3badbbY+ttv62G7bzjZbn5G32/W6++qrF+7yYTayqjquuzfPPceysd22nW22Prbb+thu2842W59l3G7eygQAGIQwAwAYhDAb2xFzD7CkbLdtZ5utj+22PrbbtrPN1mfptptjzAAABmGPGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAg/n9QVI3qdlJqkgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}